{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "\n",
    "\n",
    "color = (255,255,255)\n",
    "# defined lower and upper boundaries for each color\n",
    "# Strongly recommended finding for your own camera.\n",
    "colors = {'blue': [np.array([95, 255, 85]), np.array([120, 255, 255])],\n",
    "          'red': [np.array([161, 165, 127]), np.array([178, 255, 255])],\n",
    "          'yellow': [np.array([16, 0, 99]), np.array([39, 255, 255])],\n",
    "          'green': [np.array([33, 19, 105]), np.array([77, 255, 255])]}\n",
    "trajectory = []\n",
    "\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "\n",
    "# Get device product line for setting a supporting resolution\n",
    "pipeline_wrapper = rs.pipeline_wrapper(pipeline)\n",
    "pipeline_profile = config.resolve(pipeline_wrapper)\n",
    "device = pipeline_profile.get_device()\n",
    "device_product_line = str(device.get_info(rs.camera_info.product_line))\n",
    "\n",
    "found_rgb = False\n",
    "for s in device.sensors:\n",
    "    if s.get_info(rs.camera_info.name) == 'RGB Camera':\n",
    "        found_rgb = True\n",
    "        break\n",
    "if not found_rgb:\n",
    "    print(\"The demo requires Depth camera with Color sensor\")\n",
    "    exit(0)\n",
    "\n",
    "config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "if device_product_line == 'L500':\n",
    "    config.enable_stream(rs.stream.color, 960, 540, rs.format.bgr8, 30)\n",
    "else:\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_frames():\n",
    "    # Wait for a coherent pair of frames: depth and color\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    \n",
    "    # Convert images to numpy arrays\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    \n",
    "    # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "    depth_colormap_dim = depth_colormap.shape\n",
    "    color_colormap_dim = color_image.shape\n",
    "\n",
    "    # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "    if depth_colormap_dim != color_colormap_dim:\n",
    "        resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "        images = np.hstack((resized_color_image, depth_colormap))\n",
    "    else:\n",
    "        images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "    \n",
    "    return depth_image, color_image\n",
    "\n",
    "def compute_contours(frame):\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV) #convertion to HSV\n",
    "    for name, clr in colors.items(): # for each color in colors\n",
    "        if find_color(hsv, clr):  # call find_color function above\n",
    "            c, cx, cy, area = find_color(hsv, clr)\n",
    "            compute_trajectory(frame, cx, cy)\n",
    "            compute_spill(frame, cx, cy, area)\n",
    "            cv.drawContours(frame, [c], -1, color, 3) #draw contours\n",
    "            cv.circle(frame, (cx, cy), 7, color, -1)  # draw circle\n",
    "            \n",
    "            plot_trajectory(frame)\n",
    "                \n",
    "            cv.putText(frame, name, (cx,cy), \n",
    "                        cv.FONT_HERSHEY_SIMPLEX, 1, color, 1) # put text\n",
    "\n",
    "\n",
    "def find_color(frame, points):\n",
    "    mask = cv.inRange(frame, points[0], points[1]) #create mask with boundaries \n",
    "    cnts = cv.findContours(mask, cv.RETR_TREE, \n",
    "                           cv.CHAIN_APPROX_SIMPLE) # find contours from mask\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    for c in cnts:\n",
    "        area = cv.contourArea(c)    # find how big countour is\n",
    "        if area > 5000:             # only if countour is big enough, then\n",
    "            M = cv.moments(c)\n",
    "            cx = int(M['m10'] / M['m00']) # calculate X position\n",
    "            cy = int(M['m01'] / M['m00']) # calculate Y position\n",
    "            return c, cx, cy, area\n",
    "        \n",
    "def compute_trajectory(frame, cx, cy):\n",
    "    trajectory.append([cx, cy])\n",
    "    if(len(trajectory) > 50):\n",
    "        trajectory.pop(0)\n",
    "        \n",
    "def plot_trajectory(frame):\n",
    "    for point in trajectory:\n",
    "        cv.circle(frame, (point[0], point[1]), radius=1, color=(255, 0, 0), thickness=-1)\n",
    "        \n",
    "        \n",
    "def compute_spill(frame, cx, cy, area):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "def webcam():\n",
    "    cap = cv.VideoCapture(0)\n",
    "\n",
    "    while cap.isOpened(): \n",
    "        _, frame = cap.read()\n",
    "        compute_contours(frame)  \n",
    "        cv.imshow(\"Frame: \", frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release() \n",
    "    cv.destroyAllWindows()\n",
    "\n",
    "\n",
    "def realsense():\n",
    "    try:\n",
    "        pipeline.start(config)\n",
    "        while True:\n",
    "            depth_image, color_image = get_frames()\n",
    "            frame = color_image\n",
    "            compute_contours(frame)            \n",
    "            cv.imshow(\"Realsense Camera Feed\", frame)\n",
    "        \n",
    "            if cv.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        pipeline.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "realsense()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d01aede67af52a000e9299dba81bb1cadce6b5511ce195c73da7e76597aeed4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
